{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f298f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from splinter import browser\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import time\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8947750",
   "metadata": {},
   "source": [
    "# New York Regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b420af1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 102.0.5005\n",
      "Get LATEST chromedriver version for 102.0.5005 google-chrome\n",
      "Driver [C:\\Users\\hk_la\\.wdm\\drivers\\chromedriver\\win32\\102.0.5005.61\\chromedriver.exe] found in cache\n"
     ]
    }
   ],
   "source": [
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=False)\n",
    "\n",
    "url = \"https://commons.wikimedia.org/wiki/File:Map_of_New_York_Economic_Regions.svg\"\n",
    "browser.visit(url)\n",
    "\n",
    "time.sleep(1)\n",
    "\n",
    "html = browser.html\n",
    "soup = bs(html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "785ad24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_list = soup.find(\"div\", class_=\"description\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36339464",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_list = region_list.findAll(\"li\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac0d9f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "USRegions_df = []\n",
    "counter = 0\n",
    "for region in region_list:\n",
    "    counter = 1 + counter\n",
    "    region_name = region.find(\"a\").text\n",
    "#     print(region.findAll(\"a\"))\n",
    "    numRegion = len(region.findAll(\"a\"))\n",
    "    skip_first = 0\n",
    "    for i in range(numRegion):\n",
    "        if skip_first < numRegion-1:\n",
    "            skip_first = i + 1\n",
    "            counties = region.findAll(\"a\")[skip_first].text\n",
    "            data = {'Region': region_name, \n",
    "                    'Counties': counties}\n",
    "            USRegions_df.append(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63fcb91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# USRegions_df = pd.DataFrame(USRegions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e676524",
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "01e56059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Region': 'Western New York', 'Counties': 'Orleans'},\n",
       " {'Region': 'Western New York', 'Counties': 'Genesee'},\n",
       " {'Region': 'Western New York', 'Counties': 'Wyoming'},\n",
       " {'Region': 'Western New York', 'Counties': 'Niagara'},\n",
       " {'Region': 'Western New York', 'Counties': 'Erie'},\n",
       " {'Region': 'Western New York', 'Counties': 'Chautauqua'},\n",
       " {'Region': 'Western New York', 'Counties': 'Cattaraugus'},\n",
       " {'Region': 'Western New York', 'Counties': 'Allegany'},\n",
       " {'Region': 'Finger Lakes', 'Counties': 'Monroe'},\n",
       " {'Region': 'Finger Lakes', 'Counties': 'Livingston'},\n",
       " {'Region': 'Finger Lakes', 'Counties': 'Wayne'},\n",
       " {'Region': 'Finger Lakes', 'Counties': 'Ontario'},\n",
       " {'Region': 'Finger Lakes', 'Counties': 'Yates'},\n",
       " {'Region': 'Finger Lakes', 'Counties': 'Seneca'},\n",
       " {'Region': 'Finger Lakes', 'Counties': 'Cayuga'},\n",
       " {'Region': 'Southern Tier', 'Counties': 'Steuben'},\n",
       " {'Region': 'Southern Tier', 'Counties': 'Schuyler'},\n",
       " {'Region': 'Southern Tier', 'Counties': 'Chemung'},\n",
       " {'Region': 'Southern Tier', 'Counties': 'Tompkins'},\n",
       " {'Region': 'Southern Tier', 'Counties': 'Tioga'},\n",
       " {'Region': 'Southern Tier', 'Counties': 'Chenango'},\n",
       " {'Region': 'Southern Tier', 'Counties': 'Broome'},\n",
       " {'Region': 'Southern Tier', 'Counties': 'Delaware'},\n",
       " {'Region': 'Southern Tier', 'Counties': 'Allegany'},\n",
       " {'Region': 'Central New York', 'Counties': 'Cortland'},\n",
       " {'Region': 'Central New York', 'Counties': 'Cayuga'},\n",
       " {'Region': 'Central New York', 'Counties': 'Onondaga'},\n",
       " {'Region': 'Central New York', 'Counties': 'Oswego'},\n",
       " {'Region': 'Central New York', 'Counties': 'Madison'},\n",
       " {'Region': 'North Country', 'Counties': 'St. Lawrence'},\n",
       " {'Region': 'North Country', 'Counties': 'Lewis'},\n",
       " {'Region': 'North Country', 'Counties': 'Jefferson'},\n",
       " {'Region': 'North Country', 'Counties': 'Hamilton'},\n",
       " {'Region': 'North Country', 'Counties': 'Essex'},\n",
       " {'Region': 'North Country', 'Counties': 'Clinton'},\n",
       " {'Region': 'North Country', 'Counties': 'Franklin'},\n",
       " {'Region': 'Mohawk Valley', 'Counties': 'Oneida'},\n",
       " {'Region': 'Mohawk Valley', 'Counties': 'Herkimer'},\n",
       " {'Region': 'Mohawk Valley', 'Counties': 'Fulton'},\n",
       " {'Region': 'Mohawk Valley', 'Counties': 'Montgomery'},\n",
       " {'Region': 'Mohawk Valley', 'Counties': 'Otsego'},\n",
       " {'Region': 'Mohawk Valley', 'Counties': 'Schoharie'},\n",
       " {'Region': 'Capital District', 'Counties': 'Albany'},\n",
       " {'Region': 'Capital District', 'Counties': 'Columbia'},\n",
       " {'Region': 'Capital District', 'Counties': 'Greene'},\n",
       " {'Region': 'Capital District', 'Counties': 'Warren'},\n",
       " {'Region': 'Capital District', 'Counties': 'Washington'},\n",
       " {'Region': 'Capital District', 'Counties': 'Saratoga'},\n",
       " {'Region': 'Capital District', 'Counties': 'Schenectady'},\n",
       " {'Region': 'Capital District', 'Counties': 'Rensselaer'},\n",
       " {'Region': 'Hudson Valley', 'Counties': 'Sullivan'},\n",
       " {'Region': 'Hudson Valley', 'Counties': 'Ulster'},\n",
       " {'Region': 'Hudson Valley', 'Counties': 'Dutchess'},\n",
       " {'Region': 'Hudson Valley', 'Counties': 'Orange'},\n",
       " {'Region': 'Hudson Valley', 'Counties': 'Putnam'},\n",
       " {'Region': 'Hudson Valley', 'Counties': 'Rockland'},\n",
       " {'Region': 'Hudson Valley', 'Counties': 'Westchester'},\n",
       " {'Region': 'New York City', 'Counties': 'New York'},\n",
       " {'Region': 'New York City', 'Counties': 'Manhattan'},\n",
       " {'Region': 'New York City', 'Counties': 'Bronx'},\n",
       " {'Region': 'New York City', 'Counties': 'The Bronx'},\n",
       " {'Region': 'New York City', 'Counties': 'Queens'},\n",
       " {'Region': 'New York City', 'Counties': 'Queens'},\n",
       " {'Region': 'New York City', 'Counties': 'Kings'},\n",
       " {'Region': 'New York City', 'Counties': 'Brooklyn'},\n",
       " {'Region': 'New York City', 'Counties': 'Richmond'},\n",
       " {'Region': 'New York City', 'Counties': 'Staten Island'},\n",
       " {'Region': 'Long Island', 'Counties': 'Nassau'},\n",
       " {'Region': 'Long Island', 'Counties': 'Suffolk'}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "USRegions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "e404acdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies\n",
    "import pandas as pd\n",
    "import os, fnmatch\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import time\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "def file_search():\n",
    "    # Searching for csv filenames\n",
    "\n",
    "    for root, dirs, files in os.walk(\"resources\", topdown=False):\n",
    "        resourcesVFiles = []\n",
    "        resourcesRFiles = []\n",
    "        resourcesTotFiles = []\n",
    "        for name in files:\n",
    "            if os.path.join(name).startswith(\"Volume\"):\n",
    "                resourcesVFiles.append(os.path.join(root, name))\n",
    "            elif os.path.join(name).rfind(\"total\"):\n",
    "                resourcesTotFiles.append(os.path.join(root, name))\n",
    "            else:\n",
    "                resourcesRFiles.append(os.path.join(root, name))\n",
    "    \n",
    "    # Load all relevant filenames and path to a dictionary\n",
    "    resourcesFile = {\n",
    "        \"volume_data\": resourcesVFiles,\n",
    "        \"region_data\": resourcesRFiles,\n",
    "        \"sales_tot_data\": resourcesTotFiles\n",
    "    }\n",
    "    return  resourcesFile\n",
    "\n",
    "\n",
    "def volume_file():\n",
    "\n",
    "    # Extract filenames and Path or csv files relating to volume unit\n",
    "\n",
    "    resourcesVFiles = file_search()['volume_data']\n",
    "\n",
    "    numfile = len(resourcesVFiles)\n",
    "\n",
    "    # Load Volume into dfs\n",
    "    for i in range(len(resourcesVFiles)):\n",
    "        file = resourcesVFiles[i]\n",
    "        i = i + 1\n",
    "        variable_name = f\"vol_{i}\"\n",
    "        globals()[variable_name] =  pd.read_csv(file)\n",
    "\n",
    "    # Union Join dfs\n",
    "    if numfile == 3:\n",
    "        volume_temp = pd.concat([vol_1, vol_2])\n",
    "        volume = pd.concat([volume_temp, vol_3])\n",
    "    elif numfile == 2: \n",
    "        volume = pd.concat([vol_1, vol_2])\n",
    "    else:\n",
    "        volume == vol_1\n",
    "\n",
    "    # Replace N/A with zeros\n",
    "    volume.fillna(0)\n",
    "\n",
    "    for col in volume.columns:\n",
    "        if not (col == 'Week' or col == 'Status' or col == 'Year'):\n",
    "            try:\n",
    "                volume[col] = volume[col].str.replace(\",\", \"\").astype(float)\n",
    "            except AttributeError:\n",
    "                print(f'skipped {col}')\n",
    "\n",
    "    volume_transformed = volume.fillna(0)\n",
    "\n",
    "    volume_transformed['WEDate'] = pd.to_datetime(volume_transformed.Week)\n",
    "\n",
    "    actual_vol_temp = volume_transformed.loc[(volume_transformed[\"Status\"] == \"Actual\"), :]\n",
    "    actual_vol = actual_vol_temp.to_dict(\"records\")\n",
    "\n",
    "    return actual_vol\n",
    "\n",
    "def scrape_region():\n",
    "    # Identify Counties with their Regions\n",
    "    executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "    browser = Browser('chrome', **executable_path, headless=False)\n",
    "\n",
    "    url = \"https://www.britannica.com/topic/list-of-cities-and-towns-in-the-United-States-2023068\"\n",
    "    browser.visit(url)\n",
    "\n",
    "    time.sleep(1)\n",
    "\n",
    "    html = browser.html\n",
    "    soup = bs(html, \"html.parser\")\n",
    "    sections_id = 326620\n",
    "    lst_section_id = 50\n",
    "    USRegions_df = []\n",
    "    # Loop starts\n",
    "    for x in range(lst_section_id):\n",
    "        section_id = sections_id + x\n",
    "        section_name = f'ref{section_id}'\n",
    "        section = soup.findAll(\"section\", id=section_name)[0]\n",
    "        states = section.find(\"h2\", class_=\"h1\").text\n",
    "        for cities in range(len(section.findAll(\"li\"))):\n",
    "            row = section.findAll(\"li\")[cities]\n",
    "            try:\n",
    "                row_text = row.find(\"a\").text\n",
    "            except AttributeError: \n",
    "                row_text = row.find(\"div\").text\n",
    "            data = {'state': states,\n",
    "                    'city': row_text}\n",
    "            USRegions_df.append(data)\n",
    "    browser.quit()\n",
    "\n",
    "    return USRegions_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "3daee4a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 102.0.5005\n",
      "Get LATEST chromedriver version for 102.0.5005 google-chrome\n",
      "Driver [C:\\Users\\hk_la\\.wdm\\drivers\\chromedriver\\win32\\102.0.5005.61\\chromedriver.exe] found in cache\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Can only merge Series or DataFrame objects, a <class 'list'> was passed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7928/2701463852.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0msales_tot_transformed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msales_tot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[0msales_tot_transformed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msales_tot_transformed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscrape_region\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleft_on\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Geography\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright_on\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"city\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"left\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mmerge\u001b[1;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m   9188\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmerge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   9189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 9190\u001b[1;33m         return merge(\n\u001b[0m\u001b[0;32m   9191\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   9192\u001b[0m             \u001b[0mright\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[0mvalidate\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m ) -> DataFrame:\n\u001b[1;32m--> 106\u001b[1;33m     op = _MergeOperation(\n\u001b[0m\u001b[0;32m    107\u001b[0m         \u001b[0mleft\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m         \u001b[0mright\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    626\u001b[0m     ):\n\u001b[0;32m    627\u001b[0m         \u001b[0m_left\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_validate_operand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 628\u001b[1;33m         \u001b[0m_right\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_validate_operand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mright\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    629\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0morig_left\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_left\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    630\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0morig_right\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_right\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m_validate_operand\u001b[1;34m(obj)\u001b[0m\n\u001b[0;32m   2274\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2275\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2276\u001b[1;33m         raise TypeError(\n\u001b[0m\u001b[0;32m   2277\u001b[0m             \u001b[1;34mf\"Can only merge Series or DataFrame objects, a {type(obj)} was passed\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2278\u001b[0m         )\n",
      "\u001b[1;31mTypeError\u001b[0m: Can only merge Series or DataFrame objects, a <class 'list'> was passed"
     ]
    }
   ],
   "source": [
    "# def tot_file():\n",
    "\n",
    "    # Extract filenames and Path or csv files relating to volume unit\n",
    "\n",
    "resourcesTotFiles = file_search()['sales_tot_data']\n",
    "\n",
    "numfile = len(resourcesTotFiles)\n",
    "\n",
    "# Load Volume into dfs\n",
    "for i in range(len(resourcesTotFiles)):\n",
    "    file = resourcesTotFiles[i]\n",
    "    i = i + 1\n",
    "    variable_name = f\"tot_{i}\"\n",
    "    globals()[variable_name] =  pd.read_csv(file)\n",
    "\n",
    "if numfile == 3:\n",
    "    sales_tot_temp = pd.concat([tot_1, tot_2])\n",
    "    sales_tot = pd.concat([sales_tot_temp, tot_3])\n",
    "elif numfile == 2: \n",
    "    sales_tot = pd.concat([tot_1, tot_2])\n",
    "else:\n",
    "    sales_tot == tot_1\n",
    "\n",
    "sales_tot_transformed = sales_tot.fillna(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c86716",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_tot_transformed[sales_tot_transformed['Region'].isna()]['Geography'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27cb0d1",
   "metadata": {},
   "source": [
    "# https://www.britannica.com/topic/list-of-cities-and-towns-in-the-United-States-2023068"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "3854149c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 102.0.5005\n",
      "Get LATEST chromedriver version for 102.0.5005 google-chrome\n",
      "Driver [C:\\Users\\hk_la\\.wdm\\drivers\\chromedriver\\win32\\102.0.5005.61\\chromedriver.exe] found in cache\n"
     ]
    }
   ],
   "source": [
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=False)\n",
    "\n",
    "url = \"https://www.britannica.com/topic/list-of-cities-and-towns-in-the-United-States-2023068\"\n",
    "browser.visit(url)\n",
    "\n",
    "time.sleep(1)\n",
    "\n",
    "html = browser.html\n",
    "soup = bs(html, \"html.parser\")\n",
    "sections_id = 326620\n",
    "lst_section_id = 50\n",
    "USRegions_df = []\n",
    "# Loop starts\n",
    "for x in range(lst_section_id):\n",
    "    section_id = sections_id + x\n",
    "    section_name = f'ref{section_id}'\n",
    "    section = soup.findAll(\"section\", id=section_name)[0]\n",
    "    states = section.find(\"h2\", class_=\"h1\").text\n",
    "    for cities in range(len(section.findAll(\"li\"))):\n",
    "        row = section.findAll(\"li\")[cities]\n",
    "        try:\n",
    "            row_text = row.find(\"a\").text\n",
    "        except AttributeError: \n",
    "            row_text = row.find(\"div\").text\n",
    "        data = {'state': states,\n",
    "                'city': row_text}\n",
    "        USRegions_df.append(data)\n",
    "USRegions_df = pd.DataFrame(USRegions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "1b3dbf67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Alexander City</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Andalusia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Anniston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Athens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Atmore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1956</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>Sheridan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1957</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>Ten Sleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1958</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>Thermopolis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1959</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>Torrington</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1960</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>Worland</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1961 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        state            city\n",
       "0     Alabama  Alexander City\n",
       "1     Alabama       Andalusia\n",
       "2     Alabama        Anniston\n",
       "3     Alabama          Athens\n",
       "4     Alabama          Atmore\n",
       "...       ...             ...\n",
       "1956  Wyoming        Sheridan\n",
       "1957  Wyoming       Ten Sleep\n",
       "1958  Wyoming     Thermopolis\n",
       "1959  Wyoming      Torrington\n",
       "1960  Wyoming         Worland\n",
       "\n",
       "[1961 rows x 2 columns]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "USRegions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "c47c5ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_tot_transformed = sales_tot_transformed.merge(USRegions_df, left_on=\"Geography\", right_on=\"city\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "0e921139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Geography</th>\n",
       "      <th>Timeframe</th>\n",
       "      <th>Current Year Week Ending</th>\n",
       "      <th>Type</th>\n",
       "      <th>ASP Current Year</th>\n",
       "      <th>Total Bulk and Bags Units</th>\n",
       "      <th>4046 Units</th>\n",
       "      <th>4225 Units</th>\n",
       "      <th>4770 Units</th>\n",
       "      <th>TotalBagged Units</th>\n",
       "      <th>SmlBagged Units</th>\n",
       "      <th>LrgBagged Units</th>\n",
       "      <th>X-LrgBagged Units</th>\n",
       "      <th>Bulk GTIN</th>\n",
       "      <th>state</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Albany</td>\n",
       "      <td>Weekly</td>\n",
       "      <td>2020-01-06 00:00:00</td>\n",
       "      <td>Conventional</td>\n",
       "      <td>1.155100</td>\n",
       "      <td>161726.12</td>\n",
       "      <td>3737.00</td>\n",
       "      <td>140642.19</td>\n",
       "      <td>184.16</td>\n",
       "      <td>10996.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6166.13</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albany</td>\n",
       "      <td>Weekly</td>\n",
       "      <td>2020-01-06 00:00:00</td>\n",
       "      <td>Conventional</td>\n",
       "      <td>1.155100</td>\n",
       "      <td>161726.12</td>\n",
       "      <td>3737.00</td>\n",
       "      <td>140642.19</td>\n",
       "      <td>184.16</td>\n",
       "      <td>10996.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6166.13</td>\n",
       "      <td>New York</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Albany</td>\n",
       "      <td>Weekly</td>\n",
       "      <td>2020-01-06 00:00:00</td>\n",
       "      <td>Conventional</td>\n",
       "      <td>1.155100</td>\n",
       "      <td>161726.12</td>\n",
       "      <td>3737.00</td>\n",
       "      <td>140642.19</td>\n",
       "      <td>184.16</td>\n",
       "      <td>10996.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6166.13</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Albany</td>\n",
       "      <td>Weekly</td>\n",
       "      <td>2020-01-12 00:00:00</td>\n",
       "      <td>Conventional</td>\n",
       "      <td>1.227609</td>\n",
       "      <td>116738.30</td>\n",
       "      <td>3649.24</td>\n",
       "      <td>90717.11</td>\n",
       "      <td>203.78</td>\n",
       "      <td>16359.88</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5808.29</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Albany</td>\n",
       "      <td>Weekly</td>\n",
       "      <td>2020-01-12 00:00:00</td>\n",
       "      <td>Conventional</td>\n",
       "      <td>1.227609</td>\n",
       "      <td>116738.30</td>\n",
       "      <td>3649.24</td>\n",
       "      <td>90717.11</td>\n",
       "      <td>203.78</td>\n",
       "      <td>16359.88</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5808.29</td>\n",
       "      <td>New York</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16931</th>\n",
       "      <td>West</td>\n",
       "      <td>Weekly</td>\n",
       "      <td>2022-03-27 00:00:00</td>\n",
       "      <td>Organic</td>\n",
       "      <td>2.132444</td>\n",
       "      <td>279969.07</td>\n",
       "      <td>16833.47</td>\n",
       "      <td>19138.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>89663.57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>154333.89</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16932</th>\n",
       "      <td>Total U.S.</td>\n",
       "      <td>Weekly</td>\n",
       "      <td>2022-04-17 00:00:00</td>\n",
       "      <td>Organic</td>\n",
       "      <td>1.774314</td>\n",
       "      <td>2073388.73</td>\n",
       "      <td>98894.63</td>\n",
       "      <td>93306.07</td>\n",
       "      <td>412.89</td>\n",
       "      <td>1366905.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>513869.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16933</th>\n",
       "      <td>Total U.S.</td>\n",
       "      <td>Weekly</td>\n",
       "      <td>2022-04-10 00:00:00</td>\n",
       "      <td>Organic</td>\n",
       "      <td>1.734692</td>\n",
       "      <td>2135495.11</td>\n",
       "      <td>84439.07</td>\n",
       "      <td>107442.51</td>\n",
       "      <td>315.94</td>\n",
       "      <td>1417980.89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>525316.71</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16934</th>\n",
       "      <td>Total U.S.</td>\n",
       "      <td>Weekly</td>\n",
       "      <td>2022-04-03 00:00:00</td>\n",
       "      <td>Organic</td>\n",
       "      <td>1.701004</td>\n",
       "      <td>2180929.28</td>\n",
       "      <td>73724.50</td>\n",
       "      <td>107346.93</td>\n",
       "      <td>306.77</td>\n",
       "      <td>1495281.89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>504269.19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16935</th>\n",
       "      <td>Total U.S.</td>\n",
       "      <td>Weekly</td>\n",
       "      <td>2022-03-27 00:00:00</td>\n",
       "      <td>Organic</td>\n",
       "      <td>1.712727</td>\n",
       "      <td>2062180.86</td>\n",
       "      <td>73187.08</td>\n",
       "      <td>90293.07</td>\n",
       "      <td>308.58</td>\n",
       "      <td>1410866.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>487525.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16936 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Geography Timeframe Current Year Week Ending          Type  \\\n",
       "0          Albany    Weekly      2020-01-06 00:00:00  Conventional   \n",
       "1          Albany    Weekly      2020-01-06 00:00:00  Conventional   \n",
       "2          Albany    Weekly      2020-01-06 00:00:00  Conventional   \n",
       "3          Albany    Weekly      2020-01-12 00:00:00  Conventional   \n",
       "4          Albany    Weekly      2020-01-12 00:00:00  Conventional   \n",
       "...           ...       ...                      ...           ...   \n",
       "16931        West    Weekly      2022-03-27 00:00:00       Organic   \n",
       "16932  Total U.S.    Weekly      2022-04-17 00:00:00       Organic   \n",
       "16933  Total U.S.    Weekly      2022-04-10 00:00:00       Organic   \n",
       "16934  Total U.S.    Weekly      2022-04-03 00:00:00       Organic   \n",
       "16935  Total U.S.    Weekly      2022-03-27 00:00:00       Organic   \n",
       "\n",
       "       ASP Current Year  Total Bulk and Bags Units  4046 Units  4225 Units  \\\n",
       "0              1.155100                  161726.12     3737.00   140642.19   \n",
       "1              1.155100                  161726.12     3737.00   140642.19   \n",
       "2              1.155100                  161726.12     3737.00   140642.19   \n",
       "3              1.227609                  116738.30     3649.24    90717.11   \n",
       "4              1.227609                  116738.30     3649.24    90717.11   \n",
       "...                 ...                        ...         ...         ...   \n",
       "16931          2.132444                  279969.07    16833.47    19138.13   \n",
       "16932          1.774314                 2073388.73    98894.63    93306.07   \n",
       "16933          1.734692                 2135495.11    84439.07   107442.51   \n",
       "16934          1.701004                 2180929.28    73724.50   107346.93   \n",
       "16935          1.712727                 2062180.86    73187.08    90293.07   \n",
       "\n",
       "       4770 Units  TotalBagged Units  SmlBagged Units  LrgBagged Units  \\\n",
       "0          184.16           10996.65              0.0              0.0   \n",
       "1          184.16           10996.65              0.0              0.0   \n",
       "2          184.16           10996.65              0.0              0.0   \n",
       "3          203.78           16359.88              0.0              0.0   \n",
       "4          203.78           16359.88              0.0              0.0   \n",
       "...           ...                ...              ...              ...   \n",
       "16931        0.00           89663.57              0.0              0.0   \n",
       "16932      412.89         1366905.16              0.0              0.0   \n",
       "16933      315.94         1417980.89              0.0              0.0   \n",
       "16934      306.77         1495281.89              0.0              0.0   \n",
       "16935      308.58         1410866.15              0.0              0.0   \n",
       "\n",
       "       X-LrgBagged Units  Bulk GTIN     state    city  \n",
       "0                    0.0    6166.13   Georgia  Albany  \n",
       "1                    0.0    6166.13  New York  Albany  \n",
       "2                    0.0    6166.13    Oregon  Albany  \n",
       "3                    0.0    5808.29   Georgia  Albany  \n",
       "4                    0.0    5808.29  New York  Albany  \n",
       "...                  ...        ...       ...     ...  \n",
       "16931                0.0  154333.89       NaN     NaN  \n",
       "16932                0.0  513869.98       NaN     NaN  \n",
       "16933                0.0  525316.71       NaN     NaN  \n",
       "16934                0.0  504269.19       NaN     NaN  \n",
       "16935                0.0  487525.98       NaN     NaN  \n",
       "\n",
       "[16936 rows x 16 columns]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_tot_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e53bbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
